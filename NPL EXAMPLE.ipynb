{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4df121cf-4ad5-4e3d-a2a7-1d01dfd3354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk import word_tokenize,pos_tag,ngrams \n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer \n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081be2e5-5b43-4fb1-82b8-8882aedc1c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\aishwarya\n",
      "[nltk_data]     m\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\aishwarya\n",
      "[nltk_data]     m\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\aishwarya\n",
      "[nltk_data]     m\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\aishwarya m\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\aishwarya m\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') \n",
    "nltk.download('stopwords') \n",
    "nltk.download('words') \n",
    "nltk.download('averaged_perceptron_tagger') \n",
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "171d59b2-6634-4ea0-ba10-8d19f3cf6f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\" apple is looking at buying U.K. startup for $1 bilion.\n",
    "     Artificial Intelligence is the future of technology!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4584ae4b-5953-4e27-ab5f-e7d6f980dbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Tokens---\n",
      "['apple', 'is', 'looking', 'at', 'buying', 'U.K.', 'startup', 'for', '$', '1', 'bilion', '.', 'Artificial', 'Intelligence', 'is', 'the', 'future', 'of', 'technology', '!']\n"
     ]
    }
   ],
   "source": [
    "tokens=word_tokenize(text) \n",
    "print(\"---Tokens---\") \n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d35a2c1-90a4-4d7e-8b89-0576b13721a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after stopword removal: ['apple', 'looking', 'buying', 'startup', 'bilion', 'Artificial', 'Intelligence', 'future', 'technology']\n"
     ]
    }
   ],
   "source": [
    "filtered=[w for w in tokens if w.isalpha() and w.lower() not in stopwords.words('english')] \n",
    "print(\"after stopword removal:\",filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9a64e50-f7e5-41d4-8221-34b7c1447541",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('en_core_web_sm') \n",
    "doc=nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4068fa1-2038-41c7-b7ca-d6a18a864121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---POS Tagging---\n",
      "            -->SPACE\n",
      "apple       -->NOUN\n",
      "is          -->AUX\n",
      "looking     -->VERB\n",
      "at          -->ADP\n",
      "buying      -->VERB\n",
      "U.K.        -->PROPN\n",
      "startup     -->VERB\n",
      "for         -->ADP\n",
      "$           -->SYM\n",
      "1           -->NUM\n",
      "bilion      -->NOUN\n",
      ".           -->PUNCT\n",
      "\n",
      "           -->SPACE\n",
      "Artificial  -->PROPN\n",
      "Intelligence-->PROPN\n",
      "is          -->AUX\n",
      "the         -->DET\n",
      "future      -->NOUN\n",
      "of          -->ADP\n",
      "technology  -->NOUN\n",
      "!           -->PUNCT\n"
     ]
    }
   ],
   "source": [
    "print('---POS Tagging---')\n",
    "for token in doc: \n",
    "    print(f\"{token.text:<12}-->{token.pos_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "512a10f3-9d06-4010-b850-2d6bb5cb0cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---named entites---\n",
      "U.K.           -->GPE\n",
      "$1 bilion      -->MONEY\n",
      "Artificial Intelligence-->ORG\n"
     ]
    }
   ],
   "source": [
    "print('---named entites---') \n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text:<15}-->{ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37d1a6ad-3b6d-40d5-81d3-e167e5479427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple' 'artificial' 'at' 'bilion' 'buying' 'for' 'future' 'intelligence'\n",
      " 'is' 'looking' 'of' 'startup' 'technology' 'the']\n",
      "<bound method _cs_matrix.toarray of <Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 14 stored elements and shape (1, 14)>>\n"
     ]
    }
   ],
   "source": [
    "vect=CountVectorizer() \n",
    "bow=vect.fit_transform([text]) \n",
    "print(vect.get_feature_names_out()) \n",
    "print(bow.toarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ef75309-77c6-4ddb-9318-fe5a9b8e63d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple' 'artificial' 'at' 'bilion' 'buying' 'for' 'future' 'intelligence'\n",
      " 'is' 'looking' 'of' 'startup' 'technology' 'the']\n",
      "<bound method _cs_matrix.toarray of <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 14 stored elements and shape (1, 14)>>\n"
     ]
    }
   ],
   "source": [
    "tfidf_Vectorizer=TfidfVectorizer() \n",
    "tfidf=tfidf_Vectorizer.fit_transform([text]) \n",
    "print(tfidf_Vectorizer.get_feature_names_out()) \n",
    "print(tfidf.toarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "580a7e22-e472-49a7-9cec-d2a6ff4b4ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams: [('apple', 'looking'), ('looking', 'buying'), ('buying', 'startup'), ('startup', 'bilion'), ('bilion', 'Artificial'), ('Artificial', 'Intelligence'), ('Intelligence', 'future'), ('future', 'technology')]\n",
      "trigrams: [('apple', 'looking', 'buying'), ('looking', 'buying', 'startup'), ('buying', 'startup', 'bilion'), ('startup', 'bilion', 'Artificial'), ('bilion', 'Artificial', 'Intelligence'), ('Artificial', 'Intelligence', 'future'), ('Intelligence', 'future', 'technology')]\n"
     ]
    }
   ],
   "source": [
    "print(\"bigrams:\",list(ngrams(filtered,2))) \n",
    "print(\"trigrams:\",list(ngrams(filtered,3))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae49e6c-938c-4b85-8881-77dff3591110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
